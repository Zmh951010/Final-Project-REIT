{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import wordcloud\n",
    "import numpy as np\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import pyecharts\n",
    "import matplotlib \n",
    "from wordcloud import WordCloud, ImageColorGenerator  \n",
    "import matplotlib.pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_answer():\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.zhihu.com/topic/19936951/top-answers\")\n",
    "    time.sleep(5)\n",
    " \n",
    "    for i in range(10):\n",
    "        browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "    divs = browser.find_elements_by_css_selector(\"div.List-item.TopicFeedItem\")\n",
    "\n",
    "    for div in divs:\n",
    "        title_info = div.find_element_by_css_selector(\"h2.ContentItem-title\").find_element_by_css_selector(\"a\")\n",
    "        url = title_info.get_attribute(\"href\")\n",
    "        title = title_info.text\n",
    "        count = button.text.split(\" \")[1]\n",
    "        content = get_top_content(url)\n",
    " \n",
    "        with open('知乎REITs.csv', 'a', newline='',encoding=\"utf-8\") as csvfile:\n",
    "            mywriter = csv.writer(csvfile)\n",
    "            mywriter.writerow([title,count,content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_content(url):\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "    content =\"\"\n",
    "    try:\n",
    "        ps = browser.find_element_by_css_selector(\"div.RichText.ztext.Post-RichText\").find_elements_by_css_selector(\"p\")\n",
    "    except Exception as e:\n",
    "        ps = browser.find_element_by_css_selector(\"span.RichText.ztext.CopyrightRichText-richText\").find_elements_by_css_selector(\"p\")\n",
    "    for p in ps:\n",
    "        content += p.text\n",
    "    browser.quit()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"知乎REITs.csv\", 'w', newline='',encoding=\"utf-8\") as csvfile:\n",
    "        mywriter = csv.writer(csvfile)\n",
    "        header = [\"titile\", \"likes\",\"content\"]\n",
    "        mywriter.writerow(header)\n",
    "get_top_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('知乎REITs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_content(df):\n",
    "    all_content = df.content.tolist()\n",
    "    #print(all_content)\n",
    "    one_content = ''\n",
    "    for content in all_content :\n",
    "        #print(content)\n",
    "        if type(content) == float:\n",
    "            continue\n",
    "        one_content +=  content\n",
    "        \n",
    "    words = jieba.cut(one_content)\n",
    "    #set stopwords\n",
    "    filepath = 'stopwords.txt'\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]   \n",
    "    stopwords.extend(['一种','and', 'you', '超过'])\n",
    "    processed_word_list = [] \n",
    "    for word in words:\n",
    "        if word not in stopwords and len(word)>1: #remove single word\n",
    "            processed_word_list.append(word)\n",
    "    return processed_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_word_list = cut_content(df)\n",
    "print(processed_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(processed_word_list, rank=100):\n",
    "    word_count100 = pd.Series(processed_word_list).value_counts().sort_values(ascending=False)[:rank]\n",
    "    word_count100_dict = word_count100.to_dict()\n",
    "    print(word_count100_dict)\n",
    "    result = \" \".join(word_count100_dict)  \n",
    "    \n",
    "    wc = WordCloud(\n",
    "        font_path=\"simhei.ttf\",\n",
    "        background_color='white',   \n",
    "        max_font_size=50,   #最大字号\n",
    "        \n",
    "    )\n",
    "    wc.generate(result)\n",
    "    plt.figure(figsize=(12,16))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('word frequency top '+str(rank)+' tag cloud', loc='Center', fontsize=26)\n",
    "    plt.show()\n",
    "    return plt.show()\n",
    "\n",
    "word_cloud(processed_word_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
